"""Constraint evaluation for the augmented Lagrangian (Â§3.2, Â§3.3, Â§6.1)."""

from __future__ import annotations

import torch
from torch import Tensor

from src.whitening.whitener import SoftZCAWhitener


# --- Penalty function (Â§3.3) ---


def al_cole_psi(g: Tensor, y: Tensor) -> Tensor:
    """AL-CoLe smooth penalty Î¨(g, y) = (max(0, 2g + y)Â² - yÂ²) / 4.

    Properties:
    - Î¨(g, y) â‰¤ 0 when g â‰¤ 0 (inactive constraints contribute non-positively).
    - âˆ‡_g Î¨ = max(0, 2g+y) / 2 (everywhere continuously differentiable).
    - Î¨(0, y) = 0 when y > 0 (smooth transition at boundary).

    Eliminates the kink at g=0 in the standard quadratic penalty Ï/2Â·max(0,g)Â²,
    which is critical for clean ESO signals and uncorrupted Adam momentum.

    Args:
        g: Constraint violation (EMA-filtered á¹½_fast, not raw).
        y: Î»_i / Ï_i (scaled dual variable).

    Returns:
        Penalty value (scalar or same shape as inputs).
    """
    inner = 2.0 * g + y
    return (torch.clamp(inner, min=0.0).pow(2) - y.pow(2)) / 4.0


# --- Lagrangian assembly (Â§3.3, Â§6.1) ---


def compute_augmented_lagrangian(
    l0_corr: Tensor,
    v_fast: Tensor,
    lambdas: Tensor,
    rhos: Tensor,
) -> Tensor:
    """Assemble the SPALF augmented Lagrangian.

    ð“›(Î¸, Î», Ï) = â„“â‚€^corr(Î¸) + Î£áµ¢ Ïáµ¢ Â· Î¨(á¹½_fast_i, Î»áµ¢/Ïáµ¢)

    IMPORTANT: Takes EMA-filtered violations (á¹½_fast), NOT raw per-batch violations.
    Data flow: raw v_i â†’ DualRateEMA.update() â†’ á¹½_fast â†’ this function.

    Args:
        l0_corr: Scalar discretization-corrected sparsity objective.
        v_fast: [3] EMA-filtered constraint violations (faith, drift, ortho).
        lambdas: [3] dual variables from ADRC controller.
        rhos: [3] adaptive penalty coefficients from CAPU.

    Returns:
        Scalar augmented Lagrangian loss for backward pass.
    """
    y = lambdas / rhos  # [3] scaled dual variables
    psi_values = al_cole_psi(v_fast, y)  # [3]
    constraint_penalty = (rhos * psi_values).sum()
    return l0_corr + constraint_penalty


# --- Violation computations (Â§3.2) ---


def compute_faithfulness_violation(
    x: Tensor,
    x_hat: Tensor,
    whitener: SoftZCAWhitener,
    tau_faith: float,
) -> Tensor:
    """C1 â€” Faithfulness: whitened-space MSE (Â§3.2).

    g_faith = (1/N) Î£ â€–xÌƒ - W_white(xÌ‚ - Î¼)â€–Â² - Ï„_faith
            = (1/N) Î£ â€–W_white(x - xÌ‚)â€–Â² - Ï„_faith
            = (1/N) Î£ (x - xÌ‚)^T Î£_Î±^{-1} (x - xÌ‚) - Ï„_faith

    Uses cached precision matrix to avoid materializing whitened reconstruction.

    Args:
        x: [B, d] raw activations (original space).
        x_hat: [B, d] SAE reconstruction (original space).
        whitener: Soft-ZCA whitener with cached precision matrix.
        tau_faith: Faithfulness threshold = (1 - RÂ²_target) * d.

    Returns:
        Scalar violation (positive = constraint violated).
    """
    diff = x - x_hat  # [B, d]
    mahal_sq = whitener.compute_mahalanobis_sq(diff)  # [B]
    return mahal_sq.mean() - tau_faith


def compute_faithfulness_violation_phase2(
    x: Tensor,
    x_hat: Tensor,
    kl_div: Tensor,
    tau_faith: float,
    kl_running_mean: Tensor,
) -> Tensor:
    """Phase 2 faithfulness: scale-normalized MSE/KL blend (Â§6.3).

    v_faith^(2) = 0.5 Â· (â€–x - xÌ‚â€–Â² - Ï„_faith) / Ï„_faith + 0.5 Â· D_KL / DÌ„_KL

    Note: MSE is in ORIGINAL space (not whitened), unlike Phase 1.

    Args:
        x: [B, d] raw activations.
        x_hat: [B, d] SAE reconstruction.
        kl_div: Scalar KL(p_orig â€– p_patched).
        tau_faith: Faithfulness threshold.
        kl_running_mean: Running mean of KL divergence (for normalization).

    Returns:
        Scalar violation.
    """
    mse = (x - x_hat).pow(2).sum(dim=1).mean()
    mse_normalized = (mse - tau_faith) / tau_faith
    kl_normalized = kl_div / kl_running_mean
    return 0.5 * mse_normalized + 0.5 * kl_normalized


def compute_drift_violation(
    W_dec_A: Tensor,
    W_vocab: Tensor,
    tau_drift: float,
) -> Tensor:
    """C2 â€” Vocabulary Drift: Frobenius norm in original space (Â§3.2).

    g_drift = â€–W_dec^(A) - W_vocabâ€–Â²_F - Ï„_drift

    Args:
        W_dec_A: [d, V] anchored decoder columns.
        W_vocab: [d, V] vocabulary/unembedding matrix.
        tau_drift: Drift threshold = Î´_driftÂ² Â· â€–W_vocabâ€–Â²_F.

    Returns:
        Scalar violation.
    """
    return (W_dec_A - W_vocab).pow(2).sum() - tau_drift


def compute_orthogonality_violation(
    z: Tensor,
    W_dec_A: Tensor,
    W_dec_B: Tensor,
    tau_ortho: float,
) -> Tensor:
    """C3 â€” Co-Activation Orthogonality: pairwise cosÂ² of active decoder columns (Â§3.2).

    g_ortho = (1/|B|) Î£_b [ (1/(|A_b|Â²-|A_b|)) Î£_{iâ‰ j âˆˆ A_b} cosÂ²(w_i, w_j) ] - Ï„_ortho

    where A_b = {j : z_{b,j} > 0} spans both strata.

    Uses Triton-accelerated kernel for fused per-sample pairwise computation.

    Args:
        z: [B, F] sparse codes (used to determine active sets).
        W_dec_A: [d, V] anchored decoder.
        W_dec_B: [d, F-V] free decoder.
        tau_ortho: Orthogonality threshold = c_ortho / d.

    Returns:
        Scalar violation.
    """
    from src.kernels.ortho_kernel import compute_ortho_triton

    return compute_ortho_triton(z, W_dec_A, W_dec_B, tau_ortho)
